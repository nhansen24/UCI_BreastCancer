{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ***UCI Breast Cancer Pipeline Project***\n",
    "###\n",
    "### Some noteworthy information from UCI:\n",
    "1) ID number\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "**Ten real-valued features are computed for each cell nucleus:**\n",
    "\n",
    "1) radius (mean of distances from center to points on the perimeter)\n",
    "2) texture (standard deviation of gray-scale values)\n",
    "3) perimeter\n",
    "4) area\n",
    "5) smoothness (local variation in radius lengths)\n",
    "6) compactness (perimeter^2 / area - 1.0)\n",
    "7) concavity (severity of concave portions of the contour)\n",
    "8) concave points (number of concave portions of the contour)\n",
    "9) symmetry\n",
    "10) fractal dimension (\"coastline approximation\" - 1)\n",
    "###\n"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Import Modules:",
   "id": "749aa01dbbbdb920"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T22:10:37.664768Z",
     "start_time": "2025-04-15T22:10:37.660931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression, Lasso, Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Import UCI Dataset &#8594; Write dataset to local csv &#8594; Search for missing values and verify shape",
   "id": "d6bb11e040930155"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T21:35:17.776891Z",
     "start_time": "2025-04-15T21:35:17.768109Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Import UCI Dataset and write to local csv\n",
    "# from ucimlrepo import fetch_ucirepo\n",
    "# breast_ca = fetch_ucirepo(id=17)\n",
    "\n",
    "# breast_ca_df = breast_ca.data.original\n",
    "# breast_ca_df.to_csv('UCI_BreastCancer.csv', index=False)\n",
    "# print('Successfully wrote dataset to csv file!')\n",
    "\n",
    "# Read csv and store as df\n",
    "df = pd.read_csv('UCI_BreastCancer.csv')\n",
    "\n",
    "# Search Dataset for missing / null values\n",
    "try:\n",
    "    if df.isnull().sum().any()>0:\n",
    "        print('NaN values found: ', df.isnull().sum())\n",
    "    else:\n",
    "        print('No NaN or null values found')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Verify features and shape\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ],
   "id": "ab5da9bbd6113d23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN or null values found\n",
      "Index(['ID', 'radius1', 'texture1', 'perimeter1', 'area1', 'smoothness1',\n",
      "       'compactness1', 'concavity1', 'concave_points1', 'symmetry1',\n",
      "       'fractal_dimension1', 'radius2', 'texture2', 'perimeter2', 'area2',\n",
      "       'smoothness2', 'compactness2', 'concavity2', 'concave_points2',\n",
      "       'symmetry2', 'fractal_dimension2', 'radius3', 'texture3', 'perimeter3',\n",
      "       'area3', 'smoothness3', 'compactness3', 'concavity3', 'concave_points3',\n",
      "       'symmetry3', 'fractal_dimension3', 'Diagnosis'],\n",
      "      dtype='object')\n",
      "(569, 32)\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Define Target (y) and Features (X) &#8594; Convert Target to Binary &#8594; Train_Test_Split()",
   "id": "a213549fdd484797"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T22:05:28.021142Z",
     "start_time": "2025-04-15T22:05:28.012704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define features and target\n",
    "y = df.Diagnosis\n",
    "X = df.drop(columns=['Diagnosis'])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Convert target data to binary and verify value_counts.\n",
    "print('\\nPrior to binary conversion: \\n',y.value_counts())\n",
    "try:\n",
    "    y = pd.DataFrame(np.where(y == 'M',1,0), columns=['Diagnosis'])\n",
    "    y = y.Diagnosis\n",
    "    print('\\nPost binary conversion: \\n',y.value_counts(),'\\n')\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)"
   ],
   "id": "c772ced577d1db74",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 31)\n",
      "(569,)\n",
      "\n",
      "Prior to binary conversion: \n",
      " Diagnosis\n",
      "B    357\n",
      "M    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Post binary conversion: \n",
      " Diagnosis\n",
      "0    357\n",
      "1    212\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "(569, 31)\n",
      "(569,)\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Preprocessing / Scaling / Exploratory Data Analysis:",
   "id": "ba831541f3d498e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T22:10:41.081296Z",
     "start_time": "2025-04-15T22:10:41.076226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "## All features are numeric\n",
    "# print(X_train.nunique())\n",
    "\n",
    "preprocess = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('preprocessor', preprocess, X_train.columns)\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clfr', RandomForestClassifier()),\n",
    "    ('clfg', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "search_space = [\n",
    "    {'clfr': RandomForestClassifier(), 'clfr__max_depth':np.linspace(5,55,10), 'clfr__n_estimators':np.linspace(10,100,10)},\n",
    "    {'clfg': GradientBoostingClassifier(), 'clfg__learning_rate':np.logspace(-4,-1,9), 'clfg__n_estimators':np.linspace(10,100,10)},\n",
    "]"
   ],
   "id": "562410bdffa1d61a",
   "outputs": [],
   "execution_count": 72
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
